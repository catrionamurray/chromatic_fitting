{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimental_chromatic_fitting import *\n",
    "from chromatic import Rainbow\n",
    "from pymc3 import Normal, Uniform, Model, HalfNormal,  plot_trace, sample_prior_predictive, sample_posterior_predictive\n",
    "from tqdm import tqdm\n",
    "from pymc3_ext import eval_in_model, optimize, sample\n",
    "from exoplanet import QuadLimbDark\n",
    "\n",
    "plt.matplotlib.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1dbde1",
   "metadata": {},
   "source": [
    "# Play with a Model where Everything's Fixed\n",
    "Let's start by setting up the parameters as all being fixed, and see if we can still generate a model. We'll set up a simple simulated transit first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6027c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = SimulatedRainbow(tlim=[-.2, .2]*u.day, R=5).inject_transit(planet_radius=0.1)\n",
    "r.imshow();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf0500",
   "metadata": {},
   "source": [
    "We'll start a `TransitModel`. This basically just moves things around in your `chromatic_model`. In general, we could imagine splitting some of the functions up to some more general class that a `TransitModel` and a `PhaseCurveModel` and a `SystematicsModel` might all inherit from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ffafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TransitModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775dd6d0",
   "metadata": {},
   "source": [
    "Let's initialize an empty model, and setup the parameters for it. In this first example, the parameters are all set to defaults and they're all fixed. See below for changing them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.initialize_empty_model()\n",
    "t.setup_parameters()\n",
    "t.summarize_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e85de4",
   "metadata": {},
   "source": [
    "Now that the parameters are defined, we can set up the orbit. As is, there's nothing that goes into defining the orbit that should be wavelength dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84ea15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.setup_orbit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75108f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.orbit.period.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792e21a",
   "metadata": {},
   "source": [
    "We can test out that the orbit is doing something reasonable by plotting the path of the planet over the time of the observation. It looks like part of a transit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with t.model:\n",
    "    x, y, z = [eval_in_model(bla, point={}) for bla in t.orbit.get_planet_position(r.time)]\n",
    "    plt.figure(figsize=(10,3))\n",
    "    theta = np.linspace(0, 2*np.pi)\n",
    "    plt.fill_between(np.cos(theta), np.sin(theta), color='gray')\n",
    "    plt.scatter(x, y, c=r.time)\n",
    "    plt.axis('scaled');\n",
    "    plt.ylim(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6656a87",
   "metadata": {},
   "source": [
    "Next, we can attach the data. This is the first time the model knows anything about how many wavelengths there are, or what the times are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e08e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.attach_data(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5aaa4",
   "metadata": {},
   "source": [
    "Next, we set up the light curves. This has to happen after the data is attached, because we need to know the actual times to set up the `.get_light_curve` and how many light curve models to generate (= the number of wavelengths). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.setup_lightcurves()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca9a57",
   "metadata": {},
   "source": [
    "Next, we set up the likelihood, meaning that we connect all the model light curves to their associated data. This is breaking things into a few different steps, but I could imagine that these are all places that we might want to change independently. For example, right now we're assuming uncorrelated Gaussian noise with no outliers, but we could quite plausibly want to use different noise distributions and/or Gaussian processes, after the basic light curve model has been set up. Of course, since we can't change any of the parameters, we can calculate a probability but we can't actually do much with it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.setup_likelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ec7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.model.check_test_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88273e3a",
   "metadata": {},
   "source": [
    "I'm still *really* shaky on how `aesara` variables work, but it looks like I was able to construct an array-like thing that matches the chromatic fluxlike shape, so we can drop it in for easy visualizations of the model. The `pymc3_ext` function `eval_in_model` was a huge help here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa32974",
   "metadata": {},
   "outputs": [],
   "source": [
    "with t.model:\n",
    "    r.fluxlike[f'exoplanet-model'] = eval_in_model(t.model_chromatic_flux, point={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.imshow_quantities(['flux', 'model', 'exoplanet-model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad665c",
   "metadata": {},
   "source": [
    "# Play with a Model where Some Parameters are Fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791a0d32",
   "metadata": {},
   "source": [
    "Obviously, just putting in fixed parameters everywhere is not the point of all this. So, let's make another dataset, and try to fit some parameters to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SimulatedRainbow(tlim=[-.2, .2]*u.day, R=5, signal_to_noise=300)\n",
    "r = s.inject_transit(planet_radius=np.linspace(0.15, 0.05, s.nwave))\n",
    "r.imshow();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175bd90b",
   "metadata": {},
   "source": [
    "The setup will look the same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d6c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TransitModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4baf57",
   "metadata": {},
   "source": [
    "The main difference now being that we're supplying some new parameters of different kinds to the initial setup. Here, we're setting `period` to be fixed at a single value. We're setting `stellar_radius` to be fitted and shared across all wavelengths. We're setting `radius_ratio` and `limb_darkening` to be fitted and unique for each wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b6b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.setup_parameters(period=3.0, \n",
    "                   stellar_radius=Fitted(Uniform, lower=0.1, upper=2.0),\n",
    "                   radius_ratio=WavelikeFitted(Normal, mu=0.1, sigma=0.05), \n",
    "                   limb_darkening=WavelikeFitted(QuadLimbDark))\n",
    "t.summarize_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0df7e9a",
   "metadata": {},
   "source": [
    "After changing that parameter setup, everything else proceeds exactly the same as before to initialize the model. I think this is effectively what happens in your various versions of `cm.initialise...`, just split in slightly different ways. Also, typing this makes me realize that we might want to consider some English + British aliases in function names ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703631ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.initialize_empty_model()\n",
    "t.setup_orbit()\n",
    "t.attach_data(r)\n",
    "t.setup_lightcurves()\n",
    "t.setup_likelihood()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546ca3e",
   "metadata": {},
   "source": [
    "*This is a little bit of a tanget, since your code works so beautifully to plot the priors and the posterior models, but I wanted to understand PyMC3 a little better.* I'm still trying to understand this better, but right now my understanding is that the \"prior predictive\" gives examples of what our datasets might look like, according to samples from the prior. That is, it's a model for the flux for each time/wavelength, with an instance of noise generated on top of it? This is slightly different than just plotted multiple version of the model, because once we start explicitly modeling noise parameters, we'll want to see what kinds of datasets can be produced, including both the central value of the model and the assumed noise around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60cbdd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with t.model:\n",
    "    prior_predictive_trace = sample_prior_predictive(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4e5ae",
   "metadata": {},
   "source": [
    "Is our actual data the kind of thing we could possibly imagine happening somewhere among the prior predictive imaginary datasets? Seems like maybe, yes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c3985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    flux_for_this_sample = np.array([prior_predictive_trace[f'wavelength_{w}_data'][i] for w in range(r.nwave)])\n",
    "    r.fluxlike[f'prior-predictive-{i}'] = flux_for_this_sample\n",
    "r.imshow_quantities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed76019",
   "metadata": {},
   "source": [
    "OK, now, let's actually run the sampler on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with t.model:\n",
    "    trace = sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8951776",
   "metadata": {},
   "source": [
    "Once we have the samples, let's draw some posterior predictive samples of imagined datasets, and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with t.model:\n",
    "    posterior_predictive_trace = sample_posterior_predictive(trace, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f223d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    flux_for_this_sample = np.array([posterior_predictive_trace[f'wavelength_{w}_data'][i] for w in range(r.nwave)])\n",
    "    r.fluxlike[f'posterior-predictive-{i}'] = flux_for_this_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc74f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.imshow_quantities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df9141c",
   "metadata": {},
   "source": [
    "Woah! That sampling is amazing; the posterior-predictive draws look qualitatively very similar to the real data! It seems to be working pretty well, at least for this (kind of easy?) toy model. I still need to connect this to all of Catriona's clever different kinds of fits and diagnostics, but for now I hope the flexible `Parameter` setup might be something useful we can start talking about? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
